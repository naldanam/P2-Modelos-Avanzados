{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Documentación modelo\n",
    "\n",
    " - Nelson Aldana 20194128\n",
    " - Maxwell Calderon 201920519\n",
    " - Diana Diaz 201331684\n",
    " - John Florez 201920529"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Procedimiento\n",
    "\n",
    "## 1. Analisis de los datos\n",
    "\n",
    " - La base de datos cuenta con cerca de 500.000 observaciones y 6 variables.\n",
    "    \n",
    " - La Variable para predecir es Price\n",
    "    \n",
    " - 2 variabble numericas Year y Mileage\n",
    "    \n",
    " - 3 Variables categóricas State, Make y Model\n",
    "\n",
    " - No se identifican valores faltantes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Exploración de modelos a ejecutar\n",
    "\n",
    "\n",
    "\n",
    "Para esta fase se identificaron 3 tipos de modelos que permiten realizar un desempeño de procesos predictivos así:\n",
    "\n",
    "\n",
    "1. Random Forest\n",
    "2. Xgboost\n",
    "3. Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.\tTransformación de la data\n",
    "\n",
    "Toda vez que los modelos seleccionados para realizar la predicción (XGBoost, Random forest y Adaboost) solo admiten variables de tipo numérico, se transforman las variables categóricas utilizando ACP y codificación binaria para obtener dos conjuntos de datos.\n",
    "\n",
    "   ### a. Analisisis de componentes principales\n",
    "   \n",
    "   Las variables categóricas se transforman en variables dummies y se utilizan los componentes principales para construir 8 variables que se entienden como la combinación lineal de las originales y explican un porcentaje importante de la varianza de los datos. A partir de esto se obtiene una tabla X de 8 columnas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### b.\tBinary\n",
    "\n",
    "Esta transformación es una codificación binaria para variables categóricas y las almacena como cadenas de bits binarias, haciendo que la data sea más ligera, se obtiene una tabla X de 27 columnas.\n",
    "\n",
    "### c.\tFactorize\n",
    "\n",
    "Esta transformación obliga a las variables categóricas a ser de tipo numérico para poder identificar valores diferentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Se implementa un diagrama de flujo propuesto en la página \n",
    "https://scikit-learn.org/stable/modules/cross_validation.html, que consiste aplicar secuencialmente los siguientes pasos: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://github.com/naldanam/P2-Modelos-Avanzados/blob/master/Project2/Imagen1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. Aplicación de Modelos\n",
    "\n",
    "  ## 4.1 Random Forest\n",
    "  \n",
    "  Se construye la función ManualCrossValidation y se toma el 70% de los datos para TRAINING y dividirlo en 10 folks para entrenar el modelo y el restante 30% para TEST. \n",
    "  \n",
    "  \n",
    "   En la evaluación del modelo se utiliza el promedio de los 10 RMSE obtenidos como medida de desempeño.\n",
    "   \n",
    "   Para el cálculo del n-estimator óptimo, se realziaron dos rangos\n",
    "   \n",
    "   - Un rango de (1, 120, 30), obteniendo un MSE de 6699 con 30 estimadores.\n",
    "   \n",
    "   - Otro rango de (20, 35, 5) obteniendo un MSE de 4179 con 25 estimadores.\n",
    "   \n",
    "A continuación, se fijo el n-estimator en 25 y se buscó el mejor Depth, para esto se inició con un rango de (1, 150, 50)  y se acoto en el intervalo con menor MSE (30, 60, 5).\n",
    "  \n",
    "  A partir de esto, obtenemos que los mejores parámetros son:\n",
    "  \n",
    "  - n_estimator=25 y depth=45, que producen un RMSE de 4984."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ## 4.1.1 Random Forest con transformación ACP\n",
    " \n",
    " Se procede de forma similar a la ejecución con transformación binaria.\n",
    " \n",
    " \n",
    "Inicialmente se busca el n_estimator que minimice el MSE, para esto se empieza con un rango de (1, 400, 50) y se acota a (1, 200, 50), encontrando que el mejor valor para el n-estimator es 100.\n",
    "\n",
    "A continuación, se procede a buscar el Depth de la misma manera. Los valores de los parámetros que minimizan el cuadrado medio del error son \n",
    "\n",
    "- n_estimators=100,max_depth=50, y proporcionan un RMSE de 5.692. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.1.2 Random Forest con Factorize\n",
    "\n",
    "De forma complementaria, se ejecutó un radom forest con factorize, el cual fue entrenado de manera similar a la descrita en los dos procedimientos anteriores, pero su cuadrado medio del error fue superior a 7000. Sin embargo, la razón principal para realizar este tipo de transformación sobre la data fue aligerar el tamaño del archivo resultante para construir la API del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.2 Adaboost\n",
    " \n",
    " Para el calculo de este modelo se realizo por la librería sklearn y se uso el 70% de los datos para TRAINING y el restante 30% para TEST.\n",
    "  \n",
    "  Con estos valores se obtuvo un MSE de 10765.\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.2 Xgboost\n",
    "\n",
    "Se construye la función ManualCrossValidation y se toma el 70% de los datos para TRAINING y dividirlo en 10 folds para entrenar el modelo y el restante 30% para TEST.\n",
    "\n",
    "Se tomaron los siguientes parametros\n",
    "\n",
    "- learning_rate = [0.1, 0.2, 0.3]\n",
    "  \n",
    "  El learning_rate permite realizar una reducción de la contribución de cada árbol.\n",
    "  \n",
    " \n",
    "- colsample_bytree =[0.5,0.65,0.8,0.9,1]\n",
    " \n",
    " El colsample_bytree son las submuestras de las columnas al construir cada árbol y es único por cada árbol.\n",
    "\n",
    "\n",
    "- cols =['learning_rate','colsample_bytree','CV']\n",
    "\n",
    " Las columnas en las cuales se van a realizar el submuestreo\n",
    "\n",
    "\n",
    "Luego de hacer un Cross-validation con 10 folks manuales, los óptimos son:\n",
    "\n",
    "- colsample_bytree=0.9\n",
    "- learning_rate=0.3\n",
    "\n",
    "Obteniendo un MSE de 8128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusiones\n",
    "\n",
    "- De acuerdo con los resultados obtenidos y realizando una comparación entre los modelos usando como estadística de desempeño el MSE, se concluye que el random forest tiene un mejor desempeño para predecir el precio de los carros usando con las variables explicativas dadas.\n",
    "\n",
    "\n",
    "- Se construye la Api con base en el modelo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Api\n",
    "\n",
    "Luego de obtener el mejor modelo para el dataset se construyo una aplicacion que permitiera optimizar el uso del mismo, así:\n",
    "\n",
    "![](https://github.com/naldanam/P2-Modelos-Avanzados/blob/master/Project2/Imagen2.png?raw=true)\n",
    "\n",
    "En esta pantalla se ingresan los sigueintes datos del Vehiculo\n",
    "\n",
    "- Price, Year, Mileage, State, Make, Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Se ejecuta la consulta\n",
    "\n",
    "![](https://github.com/naldanam/P2-Modelos-Avanzados/blob/master/Project2/Imagen3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Resultado\n",
    "\n",
    "![](https://github.com/naldanam/P2-Modelos-Avanzados/blob/master/Project2/Imagen4.png?raw=true)\n",
    "\n",
    "El código generado por la consulta es 200 lo que quiere decir que el modelo se esta ejecutando de manera optima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La URL para la consulta del API es http://ec2-18-216-149-232.us-east-2.compute.amazonaws.com:5000/, sin embargo, aunque cargamos el modelo dentro de AWS, obtuvimos lo siguiente.\n",
    "\n",
    "![](https://github.com/naldanam/P2-Modelos-Avanzados/blob/master/Project2/Imagen5.png?raw=true)\n",
    "![](https://github.com/naldanam/P2-Modelos-Avanzados/blob/master/Project2/Imagen6.png?raw=true)\n",
    "![](https://github.com/naldanam/P2-Modelos-Avanzados/blob/master/Project2/Imagen7.png?raw=true)\n",
    "![](https://github.com/naldanam/P2-Modelos-Avanzados/blob/master/Project2/Imagen8.png?raw=true)\n",
    "![](https://github.com/naldanam/P2-Modelos-Avanzados/blob/master/Project2/Imagen9.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
