{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Documentación modelo\n",
    "\n",
    " - Nelson Aldana 20194128\n",
    " - Maxwell Calderon 201920519\n",
    " - Diana Diaz 201331684\n",
    " - John Florez 201920529"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Procedimiento\n",
    "\n",
    "## 1. Analisis de los datos\n",
    "\n",
    " - La base de datos cuenta con cerca de 500.000 observaciones y 6 variables.\n",
    "    \n",
    " - La Variable para predecir es Price\n",
    "    \n",
    " - 2 variabble numericas Year y Mileage\n",
    "    \n",
    " - 3 Variables categóricas State, Make y Model\n",
    "\n",
    " - No se identifican valores faltantes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Exploración de modelos a ejecutar\n",
    "\n",
    "\n",
    "\n",
    "Para esta fase se identificaron 3 tipos de modelos que permiten realizar un desempeño de procesos predictivos así:\n",
    "\n",
    "\n",
    "1. Random Forest\n",
    "2. Xgboost\n",
    "3. Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.\tTransformación de la data\n",
    "\n",
    "Toda vez que los modelos seleccionados para realizar la predicción (XGBoost, Random forest y Adaboost) solo admiten variables de tipo numérico, se transforman las variables categóricas utilizando ACP y codificación binaria para obtener dos conjuntos de datos.\n",
    "\n",
    "   ### a. Analisisis de componentes principales\n",
    "   \n",
    "   Las variables categóricas se transforman en variables dummies y se utilizan los componentes principales para construir 8 variables que se entienden como la combinación lineal de las originales y explican un porcentaje importante de la varianza de los datos. A partir de esto se obtiene una tabla X de 8 columnas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### b.\tBinary\n",
    "\n",
    "Esta transformación es una codificación binaria para variables categóricas y las almacena como cadenas de bits binarias, haciendo que la data sea más ligera, se obtiene una tabla X de 27 columnas.\n",
    "\n",
    "### c.\tFactorize\n",
    "\n",
    "Esta transformación obliga a las variables categóricas a ser de tipo numérico para poder identificar valores diferentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Se implementa un diagrama de flujo propuesto en la página \n",
    "https://scikit-learn.org/stable/modules/cross_validation.html, que consiste aplicar secuencialmente los siguientes pasos: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://github.com/naldanam/P2-Modelos-Avanzados/blob/master/Project2/Imagen1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. Aplicación de Modelos\n",
    "\n",
    "  ## 4.1 Random Forest\n",
    "  \n",
    "  Se construye la función ManualCrossValidation y se toma el 70% de los datos para TRAINING y dividirlo en 10 folks para entrenar el modelo y el restante 30% para TEST. \n",
    "  \n",
    "  \n",
    "   En la evaluación del modelo se utiliza el promedio de los 10 RMSE obtenidos como medida de desempeño.\n",
    "   \n",
    "   Para el cálculo del n-estimator óptimo, se realziaron dos rangos\n",
    "   \n",
    "   - Un rango de (1, 120, 30), obteniendo un MSE con 30 estimadores.\n",
    "   \n",
    "   - Otro rango de (20, 35, 5) obteniendo un MSE de 4179 con 25 estimadores.\n",
    "   \n",
    "   \n",
    "### Random forest con transformación binaria\n",
    "\n",
    "Para el cálculo del n-estimator óptimo, utilizamos inicialmente un rango de (1, 120, 30), para el que se obtiene un MSE a partir del 30 estimadores. Razón por la cual acotamos a un rango de (20, 35, 5) y obtenemos un MSE de 4179 con 25 estimadores. A continuación, fijamos el n-estimator en 25 y se busca el mejor Depth, para esto iniciamos con un rango de (1, 150, 50)  y acotamos en el intervalo con menor MSE: ((30, 60, 5). A partir de esto, obtenemos que los mejores parámetros son: n_estimator=25 y depth=45, que producen un RMSE \n",
    "\n",
    "### Random forest con transformación ACP\n",
    "\n",
    "Se procede en forma similar a la ejecución con transformación binaria. Inicialmente se busca el n_estimator que minimice el MSE, para esto se empieza con un rango de (1, 400, 50) y se acota a (1, 200, 50), encontrando que el mejor valor para el n-estimator es 100. A continuación, se procede a buscar el Depth de la misma manera. Los valores de los parámetros que minimizan el cuadrado medio del error son n_estimators=100,max_depth=50, y proporcionan un RMSE de 5.692. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.2 Xgboost\n",
    "\n",
    "Se construye la función ManualCrossValidation y se toma el 70% de los datos para TRAINING y dividirlo en 10 folds para entrenar el modelo y el restante 30% para TEST.\n",
    "\n",
    "Se tomaron los siguientes parametros\n",
    "\n",
    "- learning_rate = [0.1, 0.2, 0.3]\n",
    "  \n",
    "  El learning_rate permite realizar una reducción de la contribución de cada árbol.\n",
    "  \n",
    " \n",
    "- colsample_bytree =[0.5,0.65,0.8,0.9,1]\n",
    " \n",
    " El colsample_bytree son las submuestras de las columnas al construir cada árbol y es único por cada árbol.\n",
    "\n",
    "\n",
    "- cols =['learning_rate','colsample_bytree','CV']\n",
    "\n",
    " Las columnas en las cuales se van a realizar el submuestreo\n",
    "\n",
    "\n",
    "Luego de hacer un Cross-validation con 10 folks manuales, los óptimos son:\n",
    "\n",
    "- colsample_bytree=0.9\n",
    "- learning_rate=0.3\n",
    "\n",
    "Obteniendo un MSE de 8128\n",
    "\n",
    "Al obtener estos dos parametros se encuentra que el número de estimadores debe ser 300, dando un MSE de 7631."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusiones\n",
    "\n",
    "De acuerdo con los resultados obtenidos y realizando una comparación entre los modelos usando como estadística de desempeño el MSE, se concluye que el random forest tiene un mejor desempeño para predecir el precio de los carros usando con las variables explicativas dadas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Api\n",
    "\n",
    "Luego de obtener el mejor modelo para el dataset se construyo una aplicacion que permitiera optimizar el uso del mismo, así:\n",
    "\n",
    "![](https://github.com/naldanam/P2-Modelos-Avanzados/blob/master/Project2/Imagen2.png?raw=true)\n",
    "\n",
    "En esta pantalla se ingresan los sigueintes datos del Vehiculo\n",
    "\n",
    "- Price, Year, Mileage, State, Make, Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Se ejecuta la consulta\n",
    "\n",
    "![](https://github.com/naldanam/P2-Modelos-Avanzados/blob/master/Project2/Imagen3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Resultado\n",
    "\n",
    "![](https://github.com/naldanam/P2-Modelos-Avanzados/blob/master/Project2/Imagen4.png?raw=true)\n",
    "\n",
    "El código generado por la consulta es 200 lo que quiere decir que el modelo se esta ejecutando de manera optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
